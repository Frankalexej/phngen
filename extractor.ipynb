{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate native language columns\n",
    "def concatenate_native_languages(row):\n",
    "    native_language_cols = ['Q5_1_TEXT', 'Q6_1', 'Q6_2', 'Q6_3', 'Q6_4', 'Q6_5']\n",
    "    native_languages = [str(row[col]) for col in native_language_cols if not pd.isna(row[col])]\n",
    "    return ','.join(native_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df): \n",
    "    # Filter out rows where the \"task\" column is empty\n",
    "    df = df[df['task'].notna()]\n",
    "    # extract the desired columns\n",
    "    cols = ['participant', 'token_id', 'task', 'continuum', 'vowel', 'series', 'sound_1', 'sound_2', 'img', 'same', 'trained', 'FJ_attn.keys', 'FJ_attn.rt', 'FJ_test.keys', 'FJ_test.rt']\n",
    "    df = df[cols]\n",
    "\n",
    "    # merge the FJ_attn and FJ_test columns\n",
    "    df['FJ_ans'] = df['FJ_attn.keys'].fillna(df['FJ_test.keys'])\n",
    "    df['FJ_rt'] = df['FJ_attn.rt'].fillna(df['FJ_test.rt'])\n",
    "    df.drop(['FJ_attn.keys', 'FJ_attn.rt', 'FJ_test.keys', 'FJ_test.rt'], axis=1, inplace=True)\n",
    "    \n",
    "    # Add an extra index called \"exp_order\"\n",
    "    df['exp_order'] = df.index - df.index[0] + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_data(pd.read_csv(data_dir + \"5a0c036857cee70001767a58_phx_ver10_2023-06-16_10h19.28.157.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv files\n",
    "prolific = pd.read_csv(prolific_path)\n",
    "qualtrics = pd.read_csv(qualtrics_path)\n",
    "\n",
    "# Rename the column names in prolific dataframe\n",
    "prolific.rename(columns={'Participant id': 'PROLIFIC_PID',\n",
    "                         'Age': 'age_prolific',\n",
    "                         'Sex': 'sex_prolific',\n",
    "                         'Nationality': 'nationality_prolific',\n",
    "                         'Language': 'language_prolific'}, inplace=True)\n",
    "# Keep only the approved entries in prolific\n",
    "prolific = prolific[prolific['Status'] == 'APPROVED']\n",
    "\n",
    "# Merge the prolific and qualtrics dataframes on PROLIFIC_PID\n",
    "merged = pd.merge(prolific, qualtrics, on='PROLIFIC_PID', how='left')\n",
    "\n",
    "# Add 'native_languages_qual' column\n",
    "merged['native_languages_qual'] = merged.apply(concatenate_native_languages, axis=1)\n",
    "\n",
    "# Rename the 'Q7_1_TEXT' column\n",
    "merged.rename(columns={'Q1': 'gender_qual', \n",
    "                       'Q3': 'age_qual', \n",
    "                       'Q7_1_TEXT': 'other_languages_qual'}, inplace=True)\n",
    "\n",
    "# Get all csv files in the \"data\" subdirectory\n",
    "data_files = glob.glob(data_dir + '*_phx_ver10_*.csv')\n",
    "\n",
    "keep_cols = ['PROLIFIC_PID', \"age_prolific\", \"age_qual\",\"sex_prolific\", \"gender_qual\", \"nationality_prolific\", \"language_prolific\", \"native_languages_qual\", \"other_languages_qual\"]\n",
    "\n",
    "merged = merged[keep_cols]\n",
    "\n",
    "# Rename PROLIFIC_PID to participant\n",
    "merged.rename(columns={'PROLIFIC_PID': 'participant'}, inplace=True)\n",
    "\n",
    "# Initialize an empty dataframe to store the final merged data\n",
    "final_merged_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through the data files\n",
    "for data_file in data_files:\n",
    "    # Read the csv file\n",
    "    data = pd.read_csv(data_file)\n",
    "\n",
    "    data = get_data(data)\n",
    "\n",
    "    # Extract the participant id from the file name\n",
    "    participant_id = data_file.split('_')[0].split('/')[-1]\n",
    "\n",
    "    # Merge the data with the merged dataframe based on the participant id\n",
    "    merged_data = pd.merge(merged[merged['participant'] == participant_id], data, on='participant', how='left')\n",
    "\n",
    "    # Append the merged_data to the final_merged_data dataframe\n",
    "    final_merged_data = pd.concat((final_merged_data, merged_data))\n",
    "\n",
    "# Save the final merged data to a single csv file\n",
    "final_merged_data.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
